{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a963d34",
   "metadata": {},
   "source": [
    "## **Orangeshop Project**\n",
    "### **Traitement des données sur les boutiques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1b22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47349a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>shopDescription</th>\n",
       "      <th>sunusng</th>\n",
       "      <th>ipom</th>\n",
       "      <th>weiwei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.51815</td>\n",
       "      <td>43.49507</td>\n",
       "      <td>[Orange] 64 Anglet (Avenue Belle Marion)</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.42988</td>\n",
       "      <td>46.66976</td>\n",
       "      <td>[Orange] 85 La Roche-sur-Yon (15 Rue Georges C...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.43024</td>\n",
       "      <td>46.69141</td>\n",
       "      <td>[Orange] 85 La Roche-sur-Yon (CC Les Flaneries)</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.54907</td>\n",
       "      <td>47.16152</td>\n",
       "      <td>[Orange] 44 Rezé (10 rond-point Corbinerie ,CC...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.46916</td>\n",
       "      <td>47.18722</td>\n",
       "      <td>[Orange] 44 Basse-Goulaine (CC Leclerc Pôle Sud)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude                                    shopDescription  \\\n",
       "0   -1.51815  43.49507           [Orange] 64 Anglet (Avenue Belle Marion)   \n",
       "1   -1.42988  46.66976  [Orange] 85 La Roche-sur-Yon (15 Rue Georges C...   \n",
       "2   -1.43024  46.69141    [Orange] 85 La Roche-sur-Yon (CC Les Flaneries)   \n",
       "3   -1.54907  47.16152  [Orange] 44 Rezé (10 rond-point Corbinerie ,CC...   \n",
       "4   -1.46916  47.18722   [Orange] 44 Basse-Goulaine (CC Leclerc Pôle Sud)   \n",
       "\n",
       "   sunusng  ipom  weiwei  \n",
       "0        5     7      10  \n",
       "1        3     3       2  \n",
       "2        5     9       5  \n",
       "3        8     4       8  \n",
       "4        0     4       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lecture du fichier csv sur les boutiques oranges\n",
    "df = pd.read_csv(\"/home/etienne/Documents/etienne/Documents/VDE Python/EData-P1-boutique-free-plus-proche/free_shop.csv\", sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098118ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction du departement de la description\n",
    "df['departement'] = df['shopDescription'].str.extract(r'\\[Orange\\]\\s+(\\d+)')\n",
    "df['departement'] = df['departement'].astype('Int64')\n",
    "df['departement']\n",
    "\n",
    "# Extraction de la ville\n",
    "df['ville'] = df['shopDescription'].str.extract(r'\\[Orange\\]\\s+\\d+\\s+([^\\(]+)')\n",
    "df['ville'] = df['ville'].str.strip()\n",
    "df['ville']\n",
    "\n",
    "# Extraction de l'adresse\n",
    "df['adresse'] = df['shopDescription'].str.extract(r'\\(([^\\)]+)\\)')\n",
    "df['adresse'] = df['adresse'].str.strip()\n",
    "df['adresse']\n",
    "\n",
    "# nettoyage de la description et son renomage\n",
    "df['shopDescription_clean'] = df['shopDescription'].str.replace(r'^\\[Orange\\]\\s+\\d+\\s+', '', regex=True)\n",
    "df['shopDescription_clean']\n",
    "\n",
    "\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "# Initialiser le géocodeur\n",
    "geolocator = Nominatim(user_agent=\"mon_application\")\n",
    "df[\"code_postal\"], df[\"departement\"] = None, None  # Initialisation\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    time.sleep(1)  # Pause de 1 seconde pour éviter d’être bloqué\n",
    "    location = geolocator.reverse((row[\"latitude\"], row[\"longitude\"]), language=\"fr\")\n",
    "    if location and location.raw.get(\"address\"):\n",
    "        adresse = location.raw[\"address\"]\n",
    "        df.at[index, \"code_postal\"] = adresse.get(\"postcode\", \"Non trouvé\")\n",
    "# On garde les colonnes sur les boutqiues\n",
    "df.drop(columns=[\"samsung\", \"iphone\", \"huawei\"], inplace=True)\n",
    "boutique=df.drop([\"shopDescription\", \"shopDescription_clean\"], axis=1)\n",
    "boutique1 = pd.DataFrame(columns=[\"id_boutique\", \"nom\", \"id_gestionnaire_stock\", \"code_postal\", \"departement\", \"num_telephone\", \"email\"])\n",
    "\n",
    "# Définir les types après la création\n",
    "boutique1 = boutique1.astype({\n",
    "    \"id_boutique\": int,\n",
    "    \"nom\": str,\n",
    "    \"id_gestionnaire_stock\": int,\n",
    "    \"code_postal\": int,\n",
    "    \"departement\": str,\n",
    "    \"num_telephone\": str,\n",
    "    \"email\": str\n",
    "})\n",
    "boutique[\"id_boutique\"]=boutique.index\n",
    "\n",
    "boutiqueV=pd.concat([boutique, boutique1]).copy()\n",
    "\n",
    "#Sauvegarde de la table boutique\n",
    "boutique.to_csv(\"tb_boutique.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34acfb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4f920a",
   "metadata": {},
   "source": [
    "## **Produit**\n",
    "### **Telechargement des produits sur kaggle et leur traitement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd #\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"shubhambathwal/flipkart-mobile-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lecture du fichier sur les produits\n",
    "df = pd.read_csv(\"/home/etienne/.cache/kagglehub/datasets/shubhambathwal/flipkart-mobile-dataset/versions/4/Flipkart Mobile - 2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620405a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renommons les colonnes les colonnes\n",
    "\n",
    "rename_dict = {\n",
    "    \"brand\": \"nom\",\n",
    "    \"model\": \"modele\",\n",
    "    \"base_color\": \"couleur\",\n",
    "    \"processor\": \"processeur\",\n",
    "    \"screen_size\": \"taille_écran\",\n",
    "    \"ROM\": \"capacite\",\n",
    "    \"RAM\": \"ram\",\n",
    "    \"display_size\": \"taille_affichage\",\n",
    "    \"num_rear_camera\": \"nombre_caméras_arrière\",\n",
    "    \"num_front_camera\": \"nombre_caméras_avant\",\n",
    "    \"battery_capacity\": \"capacité_batterie\",\n",
    "    \"ratings\": \"evaluations\",\n",
    "    \"num_of_ratings\": \"nombre_évaluations\",\n",
    "    \"sales_price\": \"prix\",\n",
    "    \"discount_percent\": \"pourcentage_réduction\",\n",
    "    \"sales\": \"ventes\"\n",
    "}\n",
    "\n",
    "# Renommer les colonnes\n",
    "df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff67c3",
   "metadata": {},
   "source": [
    "### **Scrappons les les images produis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d52be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "from serpapi import Client\n",
    "from urllib.parse import quote, urlsplit, urlunsplit\n",
    "from time import sleep\n",
    "from decouple import config\n",
    "\n",
    "df_unique=df.drop_duplicates(subset =\"modele\", keep = 'first').copy(deep=True)\n",
    "# === Configuration ===\n",
    "API_KEY = config(\"API_KEY\")\n",
    "client = Client(api_key=API_KEY)\n",
    "\n",
    "\n",
    "\n",
    "CSV_INPUT = \"telephones.csv\"  # Fichier d'entrée avec colonnes 'nom' et 'modele'\n",
    "CSV_OUTPUT = \"telephones_avec_images.csv\"\n",
    "DOSSIER_IMAGES = \"images_telephones\"\n",
    "os.makedirs(DOSSIER_IMAGES, exist_ok=True)\n",
    "\n",
    "\n",
    "# === Fonction : nettoyer l'URL pour éviter erreurs 400 ===\n",
    "def clean_url(url):\n",
    "   try:\n",
    "       parts = urlsplit(url)\n",
    "       path = quote(parts.path, safe=\"/\")\n",
    "       return urlunsplit((parts.scheme, parts.netloc, path, parts.query, parts.fragment))\n",
    "   except Exception:\n",
    "       return url\n",
    "\n",
    "\n",
    "# === Fonction : rechercher l'image avec SerpAPI ===\n",
    "def get_image_url_serpapi(marque, modele):\n",
    "   try:\n",
    "       query = f\"{marque} {modele} smartphone\"\n",
    "       results = client.search({\n",
    "           \"engine\": \"google_images\",\n",
    "           \"q\": query,\n",
    "           \"tbm\": \"isch\"\n",
    "       })\n",
    "       images = results.get(\"images_results\", [])\n",
    "       if images:\n",
    "           return clean_url(images[0][\"original\"])\n",
    "   except Exception as e:\n",
    "       print(f\"[ERREUR API] {marque} {modele} : {e}\")\n",
    "   return None\n",
    "\n",
    "\n",
    "# === Fonction : télécharger une image localement ===\n",
    "def telecharger_image(url, filename):\n",
    "   headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "   try:\n",
    "       r = requests.get(url, headers=headers, stream=True, timeout=10)\n",
    "       if r.status_code == 200:\n",
    "           path = os.path.join(DOSSIER_IMAGES, filename)\n",
    "           with open(path, 'wb') as f:\n",
    "               for chunk in r.iter_content(1024):\n",
    "                   f.write(chunk)\n",
    "           return True\n",
    "   except Exception as e:\n",
    "       print(f\"[ERREUR DOWNLOAD] {url} : {e}\")\n",
    "   return False\n",
    "\n",
    "\n",
    "# === Traitement ===\n",
    "\n",
    "\n",
    "# Récupération des images (limite à 100 requêtes/jour !)\n",
    "images = []\n",
    "for i, row in df_unique.iterrows():\n",
    "   nom = row.get(\"nom\", \"\")\n",
    "   modele = row.get(\"modele\", \"\")\n",
    "   print(f\"[{i+1}/{len(df_unique)}] Recherche image pour {nom} {modele}...\")\n",
    "   url = get_image_url_serpapi(nom, modele)\n",
    "   images.append(url)\n",
    "   sleep(1.5)  # Petite pause pour éviter surcharge ou blocage\n",
    "\n",
    "\n",
    "df_unique[\"image_url\"] = images\n",
    "\n",
    "\n",
    "# Téléchargement des images accessibles\n",
    "for i, row in df_unique.iterrows():\n",
    "   url = row[\"image_url\"]\n",
    "   nom = row.get(\"nom\", \"phone\")\n",
    "   modele = row.get(\"modele\", \"\")\n",
    "   if pd.notna(url):\n",
    "       filename = f\"{i}_{nom}_{modele}.jpg\".replace(\" \", \"_\")\n",
    "       print(f\"Téléchargement de {filename}\")\n",
    "       telecharger_image(url, filename)\n",
    "\n",
    "\n",
    "# Sauvegarde du CSV enrichi\n",
    "df_unique.to_csv(CSV_OUTPUT, index=False)\n",
    "print(f\"\\n✅ Script terminé. Données enregistrées dans '{CSV_OUTPUT}' et images dans '{DOSSIER_IMAGES}/'\")\n",
    "\n",
    "\n",
    "#sans_na = df_unique[df_unique['image_url'].notna()]\n",
    "\n",
    "df=df_unique.copy(deep=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d83afa",
   "metadata": {},
   "source": [
    "### **Transformation et enregistrement des données produit,marque, modele, stock**\n",
    "#### **Transformantion des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"/home/etienne/Documents/etienne/Documents/VDE Python/EData-P1-boutique-free-plus-proche/free_api/mobile_locator/df.csv\", sep=\",\")\n",
    "# Création des ID de marque\n",
    "df[\"id_marque\"] = df.groupby(\"nom\").ngroup()\n",
    "\n",
    "# Création de la table tb_marque\n",
    "tb_marque = df[[\"id_marque\", \"nom\"]].drop_duplicates().copy()\n",
    "\n",
    "\n",
    "tb_marque.rename(columns={\"nom\": \"marque\"}, inplace=True)\n",
    "\n",
    "# Création de la table tb_modele\n",
    "df[\"id_modele\"] = df.groupby([\"modele\", \"id_marque\"]).ngroup()\n",
    "tb_modele = df[[\"id_modele\", \"id_marque\", \"modele\"]].drop_duplicates().copy()\n",
    "\n",
    "# Création de la table tb_produit\n",
    "\n",
    "df[\"id_produit\"] = df.index\n",
    "df[\"produit\"]= df[[\"nom\", \"modele\", \"capacite\"]].astype(str).agg(\" \".join, axis=1)\n",
    "tb_produit = df[[\"id_produit\", \"produit\", \"id_modele\", \"prix\", \"couleur\", \"capacite\", \"ram\", \"image\"]].copy()\n",
    "tb_produit.rename(columns={\"produit\": \"nom\"}, inplace=True)\n",
    "\n",
    "\n",
    "# Création de la table tb_stock (exemple de structure vide pour l'instant)\n",
    "tb_stock = pd.DataFrame(columns=[\"id_boutique\", \"id_produit\", \"quantite\"])\n",
    "\n",
    "# Exemple pour remplir tb_stock avec des données fictives si tu veux tester\n",
    "# Supposons que chaque produit est en stock dans 1 boutique avec une quantité aléatoire\n",
    "import numpy as np\n",
    "tb_stock[\"id_boutique\"] = np.random.randint(1, 5, size=len(tb_produit))\n",
    "tb_stock[\"id_produit\"] = tb_produit[\"id_produit\"].values\n",
    "tb_stock[\"quantite\"] = np.random.randint(1, 100, size=len(tb_produit))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
